{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from IPython.display import display, Audio\n",
    "from kokoro import KModel, KPipeline\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_ID = \"hexgrad/Kokoro-82M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(\n",
    "    repo_id=REPO_ID,\n",
    "    filename=KModel.MODEL_NAMES[REPO_ID],\n",
    "    local_dir=\"../models/kokoro\",\n",
    "    force_download=False,  # Set to True to force redownload even if the file exists\n",
    ")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = KModel(repo_id=REPO_ID, model=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Initialize pipeline\n",
    "\n",
    "KPipeline is a language-aware support class with 2 main responsibilities:\n",
    "1. Perform language-specific G2P (Grapheme-to-Phoneme), mapping (and chunking) text -> phonemes\n",
    "2. Manage and store voices, lazily downloaded from HF if needed\n",
    "\n",
    "You are expected to have one KPipeline per language. If you have multiple KPipelines, you should reuse one KModel instance across all of them.\n",
    "\n",
    "By default, KPipeline will automatically initialize its own KModel (`model=True`). With `model=False` we construct a \"quiet\" KPipeline, which means that KPipeline yields (graphemes, phonemes, None) without generating any audio. You can use this to phonemize and chunk your text in advance.\n",
    "\n",
    "A \"loud\" KPipeline _with_ a model yields (graphemes, phonemes, audio).\n",
    "\n",
    "Args:\n",
    "    lang_code: Language code for G2P processing\n",
    "    model: KModel instance, True to create new model, False for no model (default: True)\n",
    "    trf: Whether to use transformer-based G2P (default: False)\n",
    "    device: Override default device selection ('cuda' or 'cpu', or None for auto)\n",
    "        If None, will auto-select cuda if available\n",
    "        If 'cuda' and not available, will explicitly raise an error\n",
    "\n",
    "### Language codes\n",
    "\n",
    "```python\n",
    "LANG_CODES = dict(\n",
    "    # pip install misaki[en]\n",
    "    a='American English',\n",
    "    b='British English',\n",
    "\n",
    "    # espeak-ng\n",
    "    e='es',\n",
    "    f='fr-fr',\n",
    "    h='hi',\n",
    "    i='it',\n",
    "    p='pt-br',\n",
    "\n",
    "    # pip install misaki[ja]\n",
    "    j='Japanese',\n",
    "\n",
    "    # pip install misaki[zh]\n",
    "    z='Mandarin Chinese',\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline = KPipeline(lang_code=\"a\", repo_id=REPO_ID, model=model, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Generate, display, and save audio files in a loop\n",
    "\n",
    "See voices samples [here](https://huggingface.co/onnx-community/Kokoro-82M-v1.0-ONNX#voicessamples).\n",
    "\n",
    "```python\n",
    "\n",
    "def pipeline(\n",
    "    text: str | List[str],\n",
    "    voice: str | None = None,\n",
    "    speed: float | ((int) -> float) = 1,\n",
    "    split_pattern: str | None = r'\\n+',\n",
    "    model: KModel | None = None\n",
    ") -> Generator[Result, None, None]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "[Kokoro](/kˈOkəɹO/) is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, [Kokoro](/kˈOkəɹO/) can be deployed anywhere from production environments to personal projects.\n",
    "'''\n",
    "generator = pipeline(text, voice='af_heart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i, (graphemes, phonemes, audio) in enumerate(generator):\n",
    "    print(\n",
    "        \"-------------------------------\\n\"\n",
    "        f\"Audio {i}:\\n\"\n",
    "        f\"  Graphemes: {graphemes}\\n\"\n",
    "        f\"  Phonemes: {phonemes}\\n\"\n",
    "    )\n",
    "    display(\n",
    "        Audio(\n",
    "            data=audio,\n",
    "            rate=24000,  # Default sample rate for Kokoro. Increasing this value will accelerate the playback speed\n",
    "            autoplay=i==0  # Autoplays the first audio and not the others\n",
    "        )\n",
    "    )\n",
    "    # Save the audio to a file\n",
    "    # sf.write(f\"../data/output_audio/{i}.wav\", audio, 24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "read-aloud-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
