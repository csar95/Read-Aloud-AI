from io import BytesIO
import json
from typing import List, Tuple, TypedDict

import gradio as gr
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import StateGraph, END, START
from langgraph.graph.graph import CompiledGraph
import magic
import numpy as np
from openai import OpenAI
from openai._exceptions import OpenAIError
import pypdfium2 as pdfium

from src.io_schemas.output_schemas import FormattedPageText
from src.io_schemas.prompts import FORMAT_TEXT_FOR_TTS
from src.openai_api_utils.controller import OpenAIAPIController
from src.pdf_reader.helpers import detect_header_footer
from src.tts.controller import TTSModelClient
from src.utils.constants import (
    DURATION_OF_ERROR_MESSAGE,
    GEMINI_BASE_URL,
    OPENAI_API_KWARGS,
    SAMPLE_RATE,
    SILENCE_KEYWORD,
    SUPPORTED_FORMATS,
)
from src.utils.custom_exceptions import (
    OpenAIInvalidResponseFormatError,
    UnsupportedFileFormatError,
)


def generate_podcast_from_file(
    file, pages, voice, speed, duration_of_pauses, gemini_api_key, gemini_model_id
) -> Tuple[int, np.ndarray]:
    try:
        assistant = ReadAloudAssistant(
            gemini_api_key=gemini_api_key, gemini_model_id=gemini_model_id
        )
        
        config = {"configurable": {"thread_id": "1"}}

        assistant.graph.invoke(
            input={
                "file": BytesIO(file),
                "input_pages": pages,
                "pages_to_process": None,
                "text_from_pages": None,
                "formatted_text": None,
                "voice": voice,
                "speed": speed,
                "duration_of_pauses": duration_of_pauses,
                "audio": None,
                "error": None,
            },
            config=config
        )

        final_state = assistant.graph.get_state(config).values
        error = final_state["error"]
        if error:
            raise Exception(error)

        return SAMPLE_RATE, final_state["audio"]

    except OpenAIError as e:
        print(f"ERROR: {e}")
        raise gr.Error(
            message="Gemini API client is not available. Please check your API key and model ID.",
            duration=DURATION_OF_ERROR_MESSAGE,
        )

    except Exception as e:
        print(f"ERROR: {e}")
        raise gr.Error(message=str(e), duration=DURATION_OF_ERROR_MESSAGE)


class ReadAloudAgentState(TypedDict):
    """State for the ReadAloudAgent workflow.

    Attributes
    ----------
    file: BytesIO
        The uploaded file containing the text to be read aloud.
    input_pages: str
        A string representing the pages to be processed, which can be a single page
        number, a list of pages (e.g., "1,2,3"), or a range of pages (e.g., "1-3").
    pages_to_process: List[int]
        A list of integers representing the 0-indexed page numbers to be processed.
    text_from_pages: List[str]
        A list of strings containing the extracted text from the specified pages of the
        PDF file, with header and footer lines removed.
    formatted_text: str
        The formatted text suitable for Text-to-Speech (TTS) processing, generated by
        the LLM model.
    voice: str
        The voice to be used for Text-to-Speech (TTS) processing.
    speed: float
        The speed of speech for the TTS model.
    duration_of_pauses: float
        The duration of pauses in the speech (in seconds) to make it sound more natural.
    audio: np.ndarray
        The generated audio containing the speech synthesized from the formatted text.
    error: str
        An error message if any error occurs during the workflow execution.
    """
    file: BytesIO
    input_pages: str
    pages_to_process: List[int]
    text_from_pages: List[str]
    formatted_text: str
    voice: str
    speed: float
    duration_of_pauses: float
    audio: np.ndarray
    error: str


class ReadAloudAssistant:
    def __init__(self, gemini_api_key: str, gemini_model_id: str):
        self.openai_api_controller = self._setup_api_client(
            api_key=gemini_api_key, model_id=gemini_model_id
        )
        self.tts_client = TTSModelClient()
        self.graph = self.graph_definition()

    def graph_definition(self) -> CompiledGraph:
        workflow = StateGraph(ReadAloudAgentState)

        # NODES
        workflow.add_node("validate_input_pages_node", self.validate_input_pages)
        workflow.add_node("validate_file_format_node", self.validate_file_format)
        workflow.add_node("extract_text_from_pdf_node", self.extract_text_from_pdf)
        workflow.add_node("format_text_for_tts_node", self.format_text_for_tts)
        workflow.add_node("convert_text_to_speech_node", self.convert_text_to_speech)

        # EDGES
        workflow.add_edge(START, "validate_input_pages_node")
        workflow.add_conditional_edges(
            "validate_input_pages_node",
            lambda state: state["error"] is not None,
            {True: "validate_file_format_node", False: END},
        )
        workflow.add_conditional_edges(
            "validate_file_format_node",
            lambda state: state["error"] is not None,
            {True: "extract_text_from_pdf_node", False: END},
        )
        workflow.add_edge("extract_text_from_pdf_node", "format_text_for_tts_node")
        workflow.add_conditional_edges(
            "format_text_for_tts_node",
            lambda state: state["error"] is not None,
            {True: "convert_text_to_speech_node", False: END},
        )
        workflow.add_edge("convert_text_to_speech_node", END)

        return workflow.compile(checkpointer=InMemorySaver())

    @staticmethod
    def _setup_api_client(api_key: str, model_id: str) -> OpenAIAPIController:
        """
        Set up the OpenAI API client with the provided API key and initialize the controller
        for the specified model ID.

        Parameters
        ----------
        api_key : str
            The API key for the OpenAI API.
        model_id : str
            The model ID to be used for inference.

        Raises
        ------
        OpenAIError
            If the API key is invalid or if there is an issue while setting up the client.

        Returns
        -------
        OpenAIAPIController
            An instance of the OpenAIAPIController initialized with the OpenAI client and
            model ID.
        """
        if not api_key:
            raise OpenAIError("API key is required.")

        try:
            client = OpenAI(api_key=api_key, base_url=GEMINI_BASE_URL)
            print(client.models.list().to_dict())
        except Exception:
            raise OpenAIError("Invalid API key or unable to connect to the OpenAI API.")

        openai_api_ctrl = OpenAIAPIController(openai_client=client, model_name=model_id)
        return openai_api_ctrl
    
    @staticmethod
    def _get_file_format(file: BytesIO) -> str:
        """
        Get the file format of the given file.

        Parameters
        ----------
        file: io.BytesIO
            File to get the format from.

        Returns
        -------
        str
            File format.
        """
        try:
            content = file.read()
            mime = magic.Magic(mime=True)
            file_type = mime.from_buffer(content)
        finally:
            file.seek(0)

        return file_type

    def validate_input_pages(self, state: ReadAloudAgentState) -> ReadAloudAgentState:
        """
        Validate the input pages string and convert it to a 0-indexed list of integers.
        """
        input_pages = state["input_pages"]
        error = None
        page_to_process = None

        try:
            input_pages = input_pages.strip()
            if not input_pages:
                page_to_process = None
            elif "," in input_pages and "-" in input_pages:
                raise Exception("Cannot mix comma-separated and range formats.")
            elif "," in input_pages:
                page_numbers_1_indexed = [
                    int(x)
                    for x in filter(
                        lambda x: x != "", map(str.strip, input_pages.split(","))
                    )
                ]
                if any(p <= 0 for p in page_numbers_1_indexed):
                    raise Exception("Page numbers must be positive integers.")
                page_to_process = [p - 1 for p in page_numbers_1_indexed]
            elif "-" in input_pages:
                start, end = map(
                    int,
                    filter(lambda x: x != "", map(str.strip, input_pages.split("-"))),
                )
                if start <= 0 or end <= 0:
                    raise Exception("Page numbers must be positive integers.")
                if start >= end:
                    raise Exception(
                        "Start page cannot be greater than or equal to end page."
                    )
                page_to_process = list(range(start - 1, end))
            else:
                page_number = int(input_pages)
                if page_number <= 0:
                    raise Exception("Page number must be a positive integer.")
                page_to_process = [page_number - 1]
        except Exception as e:
            error = str(e)

        return {
            "pages_to_process": page_to_process,
            "error": error,
        }

    def validate_file_format(self, state: ReadAloudAgentState) -> ReadAloudAgentState:
        """
        Validate the file format of the uploaded file.
        """
        file = state["file"]
        error = None

        if self._get_file_format(file=file) not in SUPPORTED_FORMATS:
            error = str(UnsupportedFileFormatError())

        return {
            "error": error,
        }

    def extract_text_from_pdf(self, state: ReadAloudAgentState) -> ReadAloudAgentState:
        """
        Extract text from a PDF file, removing header and footer lines.
        """
        pdf_file = state["file"]
        pages_to_process = state["pages_to_process"]

        pdf = pdfium.PdfDocument(pdf_file)
        print(f"Length of PDF: {len(pdf)} pages")

        header_footer_lines = detect_header_footer(document=pdf)

        text_from_pages = []
        for page_id in pages_to_process or range(len(pdf)):
            # It seems that the package "pypdfium2" separates lines by "\r\n" by default
            page_text = pdf[page_id].get_textpage().get_text_bounded()

            # Remove lines contained in header/footer
            page_text_without_header_footer = "\n".join(
                line
                for line in page_text.splitlines()
                if line.strip() not in header_footer_lines
            )

            text_from_pages.append(page_text_without_header_footer)

        return {"text_from_pages": text_from_pages}

    def format_text_for_tts(self, state: ReadAloudAgentState) -> ReadAloudAgentState:
        """
        Format text chunks into clean, natural-language text suitable for Text-to-Speech
        (TTS) using an LLM model.
        """
        text_chunks = state["text_from_pages"]
        error = None
        formatted_document_text = ""

        for page_id, page_text in enumerate(text_chunks):
            print(
                ("-------------------------------------------------------------------")
            )
            print(f"Processing page {page_id + 1}/{len(text_chunks)}")

            # Get input texts that are needed to build the prompt
            previous_fragment = (
                f"... {formatted_document_text[-100:]}"
                if formatted_document_text
                else ""
            )
            current_page = page_text
            next_preview = (
                text_chunks[page_id + 1] if page_id + 1 < len(text_chunks) else ""
            )

            # Build the prompt object as the OpenAI API controller expects
            prompt = {
                "system_msg": FORMAT_TEXT_FOR_TTS.system_msg.format(
                    silence_keyword=SILENCE_KEYWORD,
                ),
                "user_msg": FORMAT_TEXT_FOR_TTS.user_msg.format(
                    previous_fragment=previous_fragment,
                    current_page=current_page,
                    next_preview=next_preview,
                ),
            }

            # Send the request to the OpenAI/Gemini API
            # FIXME: ADD RETRY FUNCTIONALITY AFTER 1 MIN WHEN RATE LIMIT ERROR
            chat_completion, elapsed_time_s, retries_taken = (
                self.openai_api_controller.send_request(
                    prompt=prompt,
                    response_format=FORMAT_TEXT_FOR_TTS.output_json,
                    **OPENAI_API_KWARGS,
                )
            )
            num_attempts = retries_taken + 1
            print(
                f"Received response from OpenAI API. Response: {chat_completion}\n"
                f"num_attempts: {num_attempts}\n"
                f"response_time (s): {elapsed_time_s:.2f}"
            )

            # Validate response format. Raises custom exception if the response does not match the `FormattedPageText` schema
            response_msg = chat_completion.choices[0].message.content
            try:
                formatted_page_text = FormattedPageText(**json.loads(response_msg))
                formatted_document_text += f" {formatted_page_text.text}"
            except Exception as e:
                error = str(OpenAIInvalidResponseFormatError())

        return {
            "formatted_text": formatted_document_text,
            "error": error,
        }

    def convert_text_to_speech(self, state: ReadAloudAgentState) -> ReadAloudAgentState:
        """
        Converts text to speech using the TTS model. To do so, it splits the text into
        chunks based on the "silence" keyword, and generates audio for each chunk. This
        is done to add pauses in the speech so it sounds more natural.
        """
        text = state["formatted_text"]
        audio_chunks = []
        silence = np.zeros(
            int(SAMPLE_RATE * state["duration_of_pauses"]), dtype=np.float32
        )

        text_split_by_pauses = filter(
            lambda x: x != "", map(str.strip, text.split(SILENCE_KEYWORD))
        )
        for text_chunk_id, text_between_pauses in enumerate(text_split_by_pauses):

            audios_from_text_between_pauses = self.tts_client.text_to_speech(
                text=text_between_pauses, voice=state["voice"], speed=state["speed"]
            )

            if text_chunk_id > 0:
                audios_from_text_between_pauses = np.concatenate(
                    [silence, audios_from_text_between_pauses]
                )

            audio_chunks.append(audios_from_text_between_pauses)

        audio = np.concatenate(audio_chunks)
        
        return {"audio": audio}
